{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Differential Gene Expression Notebook\nWelcome to the Differential Gene Expression workflow for the SSRP workshop. This notebook will cover step-by-step in greater details the downstream RNA-seq analyses. \n\nAs this is built to operate on our [Binderhub](https://binderhub.readthedocs.io/en/latest/index.html), the environment has been preconfigured with appropriate software installed. These softwares will be called as needed. To view them, please see the environment file within the binder directory. If you try to run this notebook on a local machine without properly installing each software package, it will not operate correctly.\n\nThis is an attenuated workflow focusing on just the downstream analyses. For a walkthrough that includes the upstream processing, you can see the [full workshop here.](https://github.com/RU-MaGIC-Classes/SSRP_Workshop) \n\nAs this is focused on just the downstream, this will be exclusively in R for ease. \n\n### Analyses steps\nSince we will be skipping the first few, this is a summary of what has/will be performed\n- Primary Analysis: Initial demultiplexing and conversion from raw image files to .fastq files. This should include initial sequencing QC. \n- Secondary Analysis: The alignment steps and associated QC. This should include things like removal of garbage reads, ambiguous bases, and for RNAseq quantification of things like ribosomal content. \n- Tertiary analysis: The steps we will start with here. The alignment and feature generation was performed upstream and we start with those files to perform the actual differential gene expression comparisons. \n- Quartenary analysis: We will also perform some of these, this includes visualization and things like pathway analysis, but are only limited by your biological question's contraints. "},{"metadata":{},"cell_type":"markdown","source":"## Tertiary analysis start\nNow that we have determined we have a quality mapping and we have our table of gene counts, we are ready for the next step- differential gene expression analysis. One of the most prolificly utilized is [DESeq2.](https://bioconductor.org/packages/release/bioc/html/DESeq2.html)\n\nSpecifically for RNA-seq experiments like this, we need to take into account several aspects of the biology at play for the statistics. Primarily, a standard t-test assumes a normal distribution. Like a coin flip- If you flip a coin 50 times per test and do 50 test, you would expect the brunt of the output to be near the 25 heads/25 tails, with it being less and less likely to get 1 heads/49 tails or 1 tails/49 heads. That would be a normal distribution. With RNA-seq, we expect to see thousands of \"tests\" (genes) with many of them having few coin flips (reads) and then a select few having a larger portion of reads. This is more comparable to the lottery, many many will play, some will win a little bit, and very few will hit the jackpot. This type of distribution is usually called a Poisson distribution. RNA-seq goes even a bit further and no longer assumes that the mean and variance will be the same, and instead assumes that the variance is independent of the mean. This is called negative binomial distribution, and as you can see below fits an RNA-seq distribution.\n\n![https://biohpc.cornell.edu/doc/RNA-Seq-2019-Lecture3.pdf](img/nb_mean_var.png)\n\nYou also have to consider how to normalize your data. This is critical in RNA-seq data for the following effects:\n\n- Significance due to different sequencing depth. If Sample A is twice as deep as Sample B, well then the genes will look twice as expressed\n- Significance due to gene size. If Gene X is twice as long as Gene Y, you would expect more reads to map to Gene X since more of the original RNA would come from the larger gene, and therefore Gene X will look more expressed than Gene Y\n- Significance due to RNA depth/composition. There will be several genes that are the most expressed based on the negative binomial distribution. These \"super signals\" will reduce the visibility of other signals. I always think of a car with those stupid bright HID LED lights driving at night looks like the light of the sun, and then the next car with normal headlights looks like its lights arent even on. Similar concept.\n\nWith DESeq2, we fortunately can take into account these normalizations which we will go into a bit more below."},{"metadata":{},"cell_type":"markdown","source":"### Load the required libraries\nThis is where we load all the various libraries that we will be needing for the analyses. "},{"metadata":{"trusted":true},"cell_type":"code","source":"library(DESeq2)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary('pheatmap')\nlibrary(RColorBrewer)\nlibrary(ggplot2)\nlibrary('PCAtools')\nlibrary(plotly)\nlibrary(EnhancedVolcano)\nlibrary(scatterplot3d)\n\nlibrary(clusterProfiler)\nlibrary(msigdbr)\nlibrary(stringr)\nlibrary(enrichplot)\n#These below arent true libraries, but are specific parameters we will use for the quartenary analysis. \norganism='org.Mm.eg.db'\nkorg='mmu'\nmsig_org='Mus musculus'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the appropriate files\nNow that the libraries are loaded, we need to import the files with the data that comes from secondary analysis. For RNA-seq, this can include a raw hit count file like what we have here. Other outputs could include things like Salmon TPMs etc. \n\nYou also must have a metadata file. Metadata is all of the associated data for each sample such as group name, maybe some clinical features etc. "},{"metadata":{},"cell_type":"markdown","source":"#### The input hit count file\nThis is where we load first the hit count file. This could be a comma or tab delimited file (csv or tsv)\nSo you may need to change the sep parameter as needed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"filecontents <- read.csv('./input_data/merged_gene_counts.txt', header=T, sep='\\t', row.names=1)\n\n#In this case, the file has both the ensembl ID and gene symbol. We only want to use the ensembl ID as it is unqiue for each gene\n#We also then order the columns for parsing later\ncounts <- filecontents[, -c(1)]\ncounts <- counts[,order(names(counts))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Creating a table to parse the ensembl ID to gene symbol\nAs mentioned above, the input data has both the ensembl ID and gene symbol. Ensembl IDs are not exactly human readable, but they are unique for each region and each region has one. So we like to use those for most functions. Building a quick table that keeps the ensembl ID paired with each gene symbol is extremely useful to parse that apart later and make easier visualizations. "},{"metadata":{"trusted":true},"cell_type":"code","source":"genetable <- subset(filecontents, select=c(1))\nnames(genetable)[1] <- 'Geneid'\ngenetable$Gene <- rownames(genetable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The metadata file\nThis file should contain all of the different non-RNA based data points. At its most simple form, it should have the sample names and what groupings you have. In more complication experiments this will also include clinical features, batching information, etc. "},{"metadata":{"trusted":true},"cell_type":"code","source":"filecontents = read.csv('./input_data/meta.csv', header=T, sep=',', row.names=1)\n\n#Now since we have already ordered out hit count data, we can now order the metadata to keep everything aligned. \nsampletable <- filecontents[order(row.names(filecontents)),]\ncountdata <- as.matrix(counts)[, colnames(counts) %in% rownames(sampletable)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Performing DESeq\nNow that you've loaded your data and got it inputted correctly, you need to consider how DESeq2 performs differential gene expression analysis and the normalization mentioned above. You will need to:\n\n- Model the raw counts for each gene\n    - Estimate size factors. Normalizes the data using a median of ratios method\n    - Estimate gene-wise dispersion. The spread of variability in the data.\n    - Fit and shrink to gene-wise dispersion. For the RNA-depth/composition comparison, assumes that similar expression levels have similar dispersion and can be shrunk together to the generalized fit.\n    - Generalized Linear Model fit for each gene\n- Shrink log2 fold changes if applicable. This wont change the output stats, but will reduce the variance of the samples to the means of the gene, and can make for different visualizations.\n- Statistically test for differential gene expression (more detail below)\n\nAs briefly touched on above, this will help you normalize the data to take into account sequencing depth, gene size, and RNA depth/composition. All together, this starts to look like:\n\n![https://github.com/hbctraining/DGE_workshop_salmon/blob/master/img/deseq_dispersion2.png](img/deseq_dispersion2.png)\n\nYou can see how it brings the normalized counts onto a properly fit dispersion pattern.\n\nWe also need to define our design. In this case, it is set up to be as simple as possible. This is always the best way to design an experiment- reduce the variables as much as you can so that the differences you see are derived from the question at hand. In this case, we already have this defined in our metadata as the Group column, and then we build the DESeq Matrix for processing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sampletable$condition <- factor(sampletable$Group)\ndds <- DESeqDataSetFromMatrix(countData=countdata, colData=sampletable, design=~ condition)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the end one of the great things about DESeq2, is that it covers each of the aspects mentioned above in terms of normalizing and if you manually want to adjust them you can, but it will automatically perform each of these steps with a simple command:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dds <- DESeq(dds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once that has completed, we can now look at the dispersion for our samples to make sure it looks appropriate. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plotDispEsts(dds, main=\"Dispersion plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample clustering and relatedness\nNow at this step it also is good practice to look at how related samples are, which can also act as a mild QC to check that there werent any obvious sample mix ups. In this case, we will do a transformation on the data for visualization purposes, and then we will do a sample relationship distance matrix and PCA plot.\n\nBoth distance matrices and PCA plots are incredibly useful tools. PCA is primarily for dimensionality reduction- reducing your thousands of RNAseq genes to a smaller number of vectors that contain the variance. This can be more agnostic, as more similar samples will group together and more dissimilar samples will be farther apart. For PCA I like to use [PCATools](https://bioconductor.org/packages/release/bioc/html/PCAtools.html) for its ease of use as well as ability to correlate clinical data to eigenvectors (if applicable). \nDistance matrices can be a bit different since you are measuring distances between samples in either an agglomerative or divisive fashion. Generally for RNAseq we will use agglomerative hierarchal clustering as done below- based on euclidean distance of the samples. \n\nTo look at this, we can use a variety of values as input. You can start with just the raw counts, but that is not advised since there is no correction in place yet. Usually it is better practice to at least use the partially normalized counts as done here, which pulls the normalized hit counts from the DESeq object. "},{"metadata":{"trusted":true},"cell_type":"code","source":"p <- pca(counts(dds, normalized=TRUE), metadata=sampletable, removeVar=0.1)\nuncorrected_pca <- biplot(p, colby='Group',\n            legendPosition='top', legendLabSize=16, legendIconSize=8.0,\n            pointSize=6,\n            labSize=5)\nprint(uncorrected_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though this partially takes in to account the normalization, it does not fully use the data from the DESeq model. To pull out that, you need either the Variance Stabilizing Transformation (vst) or the regularized log (rlog) values. Both will produce log2 values of the data, VST is the faster option and generally is no different than rlog. rlog is superior when there are variant size factors between your groups- ie one group has 8 samples and the other has 4. Here we will use VST since our groups are all equal. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract the VST data\nvst <- vst(dds,blind=TRUE)\n\n#Pull the assay data as a matrix. \nmat <- assay(vst)\n\n## These next two lines Ive commented out as examples. This is one way you could perform a batch correction. \n#mm <- model.matrix(~condition, colData(vst))\n#mat <- limma::removeBatchEffect(mat, vst$batch, design=mm)\n\n#And now we are going to plot out the PCA plot\np <- pca(mat, metadata = sampletable, removeVar = 0.1)\npca_plot <- biplot(p, colby='Group',\n               shape='batch',\n            legendPosition='top', legendLabSize=16, legendIconSize=8.0,\n            pointSize=6,\n            labSize=5)\nprint(pca_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Just as some added fun...\nYou can also take the PCA plots and make 3D plots out of them, if you ever have additional parameters you need to show. This will not be annotated- try annotating it yourself for some practice to see if you understand the various facets!"},{"metadata":{"trusted":true},"cell_type":"code","source":"par(mar=c(4,4,4,4), cex=1.0, cex.main=0.8, cex.axis=0.8)\ncolors <- c(\"#4169E1\", \"#FF0000\")\ngroups <- colors[as.numeric(sampletable$Group)]\n\nshapes = c(15,16) \nshapes <- shapes[as.numeric(sampletable$Infected)]\n\nscatterplot3d(p$rotated[,1:3], angle=-40, main=\"\", color=groups, pch=shapes, \n              xlab=paste(\"PC1, \", round(project.pca.proportionvariances[1], 2), \"%\"), \n              ylab=paste(\"PC2, \", round(project.pca.proportionvariances[2], 2), \"%\"), \n              zlab=paste(\"PC3, \", round(project.pca.proportionvariances[3], 2), \"%\"), grid=FALSE, box=FALSE, cex.symbols=2)\n\nsource('http://www.sthda.com/sthda/RDoc/functions/addgrids3d.r')\naddgrids3d(project.pca$x[,1:3], grid = c(\"xy\", \"xz\", \"yz\"))\n\nsource('http://www.sthda.com/sthda/RDoc/functions/addgrids3d.r')\naddgrids3d(project.pca$x[,1:3], grid = c(\"xy\", \"xz\", \"yz\"))\n\n\nlegend(\"right\", levels(sampleTable$Group),\n      col =  colors, pch = c(15,16))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mentioned above, the other way to visualize sample relatedness is hierarchal clustering of samples. Here will will first generate the distance matrix, then plot it out in a heatmap format."},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleDists <- as.matrix(dist(t(mat))))\nanno_cols <- which(names(sampletable)=='Group')\nannotations=metatemp[,anno_cols, drop=F]\ncolors <- colorRampPalette(rev(brewer.pal(9, \"Greys\")))(30)\n\ndistance_matrix_plot <- pheatmap(sampleDists, annotation_row=annotations, annotation_col=annotations, col=colors,\n    fontsize_col=10, fontsize_row=10,angle_col=45\n)\nprint(distance_matrix_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, these samples are looking pretty good! The different populations should be grouping together, and should be apart from the other groupings. "},{"metadata":{},"cell_type":"markdown","source":"### Actually performing differential gene comparisons\nThis is where we actually pull out the comparisons and can say \"Gene X is significantly different in Group A over Group B!\"\nFor the statistics, DESeq2 traditionally uses the Wald test. The Wald test specifically takes into account the dispersion model distance and the negative binomial distribution that we experience with RNA-seq. We then assume our null hypothesis is that there is no differential gene expression between the groups, and p is small, we can reject the null and say the gene is differentially expressed. One last thing to consider with the p-value is multiple testing correction. Traditionally p < 0.05 is considered significant (95% chance it is not by random chance), but when you are looking at thousands of genes, you'll still end up with 5% of them significant off predicted chance. One of the best corrections to use called False-Discovery Rate correction (FDR), which is the Benjamini and Hochberg method. This corrects the p-value based upon ranking the genes and accounting for the number of genes in the dataset. If you want to be even more conservative, you can use a bonferroni correction, but here we use FDR."},{"metadata":{"trusted":true},"cell_type":"code","source":"#I have a particular loop to do this- just because often times I set this up and have multiple comparisons to run. \n#I just implement my loop regardless just cause its easier for me on a code base. \n#But you set up the comparisons in the \"compares\" list. \n\ncompares <- list(\n    list('Cell1Bug','Control'),\n    list('Cell1Fungi','Control'),\n    list('Cell2Bug','Control'),\n    list('Cell2Fungi','Control')\n)\n\n#Make a quick directory to store the output files\ndir.create('./DEG/')#DEG stands for differentially expressed genes\n\n#For each comparison I then pull out the results of the deseq based on the comparisons, then perform a logfc shrink. \n#This doesnt change what is significant or not, but makes it more even for plotting purposes. \nfor(i in compares){\n    #Pull the results from the dataset and the appropriate contrasts\n    out_res <- results(dds, contrast=c('condition',i[[1]], i[[2]]), alpha=0.05)\n    #Perform the lfc shrinkage. \n    shrink <- lfcShrink(dds, contrast=c('condition',i[[1]], i[[2]]),res=out_res, type=\"normal\")\n    comp_out <- shrink[order(shrink$padj),]\n    #Parse back the normalized values. Again you can use either the log2 values from VST or normalized hit counts\n    comp_out <- merge(as.data.frame(comp_out), as.data.frame(mat),\n    by='row.names', sort=FALSE)\n    names(comp_out)[1] <- 'Gene'\n  \n    #Now this is where that table with the ensembl IDs paired with the gene symbols comes in handy\n    #You can now add that information back in so you are looking at genes that make a bit more sense\n    DataIn <- merge(as.data.frame(comp_out), as.data.frame(genetable), by=\"Gene\", sort=FALSE)\n    DataIn <- DataIn %>% relocate(GeneID, .after = Gene)\n    #Write it out as a nice file\n    write.csv(DataIn, file=paste('./DEG/',i[[1]],'_vs_',i[[2]],'.csv', sep=''))\n    #And save the comparison in R for us to use later\n    assign(paste(i[[1]],'_vs_',i[[2]], sep=''), DataIn)\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you have your statistics performed on your data and you can start looking at what biologically is going on!"},{"metadata":{},"cell_type":"markdown","source":"## Quartenary analysis start\nNow the last stages of analysis are also the most open ended- and this is considered quartenary analysis. This is where you now start to connect all the hard work you've done into some biological conclusions. In a lot of cases you'll already have some aspect you are focusing in on, maybe like the role of TH1 genes in your immune reponse to drug X or something, but other times you are purely on a fishing expedition. So here Ill leave it a bit more open ended- how would you start to explore this data?\n\nYou could look at specific genes of interest, look at just the top genes, start plotting them out in different fashions. Ill give a few examples below, but then start to explore the data and come up with some biological conclusions."},{"metadata":{},"cell_type":"markdown","source":"### Volcano Plots\nThe first place I like to start is looking at the direct group comparisons. What is different in my condition of choice to control?? Of course, you are going to want to visualize this. You can do this with standard packages, but why reinvent the wheel when there are great packages already to make it easier. In this case, I use [EnhancedVolcano](https://bioconductor.org/packages/3.13/bioc/html/EnhancedVolcano.html) as a visualization aid. \n\nFor most of these plots as we progress, I will generate one as an example. I highly recommend trying these out and generating the plots for other samples/genes etc. \n\nVolcano plots are a staple in RNA-seq analysis. These are generally used to look at the spread of differentially expressed genes between two samples. They are usually structured to show the high count of insignificant genes in on the bottom, then the more significant and alternatively regulated genes exploding out- looking a bit like a [plinian volcanic eruption](https://www.youtube.com/watch?v=VBTAcACmcgo) (hence the name- volcano plots)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#For the specific parameters to tweak, I would recommend reading the packages documentation. \ncell1bug_volcano <- EnhancedVolcano(Cell1Bug_vs_Control,\n                                   lab=as.character(Cell1Bug_vs_Control$Geneid),\n                                   title='Cell1Bug Infected versus Control',\n                                   x='log2FoldChange',\n                                   y='padj',\n                                   legendPosition='bottom',\n                                   legendLabels=c('Not significant','Log2FC','padj','padj and Log2FC'),\n                                   pCutoff=0.05,\n                                   FCcutoff=1)\n\nprint(cell1bug_volcano)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like I said above, I highly recommend fiddling with it a bit and doing the plots for the other comparisons as well here. Just add the cells!"},{"metadata":{},"cell_type":"markdown","source":"### Heatmaps\nHeatmaps can come in many flavors, sometimes you want to show just significant genes, the most variant genes between samples, maybe a list from a specific pathway etc. You also can do things like cluster the genes and samples as we did above. \n\nHere we will do a quick heatmap just looking at the top 250 most variant genes across all samples. One other note, colors used for heatmaps is constantly changing. The canonical colors are based on microarrays, with green being down and red being up. Personally that color combination drives me nuts (green means go, red is bad), so I always use something else. A very common coloration now is a red/blue combo, and also a magma gradient. There is also an increasing trend in colorblind friendly schemes, which is always great to use. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determine what the top genes are\ntopVarianceGenes <- head(order(rowVars(mat), decreasing=T), 250)\n\n#Set up a nice color palette.\nmy_colors = brewer.pal(n = 11, name = \"RdBu\")\n    my_colors = colorRampPalette(my_colors)(50)\n    my_colors = rev(my_colors)\n\n#Assign some quick column annotations\nmat_col <- data.frame(group=sampletable$Group)\nrownames(mat_col) <- colnames(mat)\n\n#Use the pheatmap package to generate the plot. In this case we will be clustering both the columns and rows\nheatmap_plot <- pheatmap(mat[topVarianceGenes,], cluster_rows=TRUE, color=my_colors,\n    show_rownames=FALSE, cluster_cols=TRUE, scale='row', fontsize=20, annotation_col=mat_col)\n\nreturn(heatmap_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As with the volcano plots, I recommend making a few more heatmaps for practice. A good idea would be to take a genelist and use those to make a specific heatmap!"},{"metadata":{},"cell_type":"markdown","source":"### Cross comparison comparisons!\nBeyond just the cross comparisons themselves, it is common to then want to compare those comparisons. There are a variety of ways to do this, but most commonly are venn diagrams and upset plots. "},{"metadata":{},"cell_type":"markdown","source":"#### Venn Diagrams\nVenn diagrams are a classic way to show overlap and uniqueness between comparisons. These are very powerful visualizations, but can become messy as the number of samples increase. Realistically two or three samples is viable, four is on the edge, five is very messy, and six+ should not be done. In that case, things should divert to upset plots. \n\nIn this case we will do all of the comparisons that we made earlier! "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make a list of the earlier comparisons\ncompares <- list(\n    list(\"Cell1Bug\", Cell1Bug_vs_Control),\n    list(\"Cell1Fungi\", Cell1Fungi_vs_Control),\n    list(\"Cell2Bug\", Cell2Bug_vs_Control),\n    list(\"Cell2Fungi\", Cell2Fungi_vs_Control)    \n)\n\n# Create an empty list to fill up as we go\nvennlist <- list()\nvenncolors <- list('#0000ff','#00ff00','#ff0000','#f0000f')\n\n#A nice little loop to go through each of the comparisons we set up above, and then pull the list of significant genes. \nfor (DataSet in compares){\n    sig_genes <- c() #The vector of significant genes to fill up as we go\n    DataIn <- as.data.frame(DataSet[2]) #Pull just the output comparison of the data\n    DataIn <- subset(DataIn, padj < 0.05) #And select the significant genes only\n    \n    #And pull the gene names just as we did before\n    original_gene_list <- DataIn$log2FoldChange\n    names(original_gene_list) <- DataIn$Gene\n    gene_list<-na.omit(original_gene_list)\n    gene_list = sort(gene_list, decreasing = TRUE)\n    genes <- names(gene_list)\n    \n    for (item in genes){\n        sig_genes <- c(sig_genes, item)\n    }\n    \n    #Get just the unique names\n    sig_genes <- unique(sig_genes) \n    #And put them in to the big list\n    vennlist[[paste(DataSet[1])]] <- sig_genes\n}\n\n#So now that the venn diagram list is built we can use it to make the actual diagram!\nfillcolors <- unlist(venncolors)\n\nvennplot <- venn.diagram(x=vennlist,\n    fill=fillcolors,\n    lwd=5,\n    lty=1,\n    cat.cex=4,\n    cex=5,\n    alpha=0.5,\n    filename=NULL\n)\n\nprint(grid.draw(vennplot))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can focus this further by selecting only up or downregulated genes as well. "},{"metadata":{},"cell_type":"markdown","source":"#### UpSet Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Since we have already built the list above, we can reuse it here. \nupset(fromList(vennlist), order.by='freq',\n    text.scale=c(2, 2, 2,\n        2, 3, 2),\n    point.size=6, \n    line.size=4,\n    mainbar.y.label='Gene intersections', sets.x.label='Significant genes',\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Likewise to venn diagrams, you can focus it by selecting up or downregulated genes only as well. "},{"metadata":{},"cell_type":"markdown","source":"### Gene Ontology/Pathway Analysis\nHaving individual genes is great, but the next step is nearly always related to groups of genes and how they could be inter-related. For the major organisms like Human/mouse/rat, there are a plethora of tools available. Things like and are commonly purchased for large scale licenses, with both available here at Rutgers. Regardless, there are also gene ontologies for a much wider berth of organisms, as well as custom gene ontologies that can be manually curated and broad pan-bacterial ontologies. \n\nHere at Rutgers, we do have licenses for both [Ingenuity Pathway Analysis (IPA)](https://digitalinsights.qiagen.com/products-overview/discovery-insights-portfolio/analysis-and-visualization/qiagen-ipa/) and [Advaita's iPathwayGuide](https://advaitabio.com/ipathwayguide/) as proprietary options. Both have their plusses and minuses, we could go in to this at depth if anyone wishes but really it comes down to which you are more comfortable with and if you really want their specially curated pathways. In reality, its often just as strong (and massively cheaper) to use open source alternatives. \n\nTo that, we will use [clusterProfiler](https://bioconductor.org/packages/release/bioc/html/clusterProfiler.html). This is a particularly powerful tool as it allows us to use multiple methods as well as multiple databases for enrichment. \n\nEnrichment is usually done either as over representation analysis (ORA) or functional class scoring (FCS), and we will explore both here. "},{"metadata":{},"cell_type":"markdown","source":"#### Over Representation Analysis\nMost proprietary platforms using ORA, occasionally with slight modifications. To perform ORA, you are selecting which features in your data you are looking at, and then comparing them to a database of ontologies/pathways. In this, your selection criteria is critical as it directly works into the significance calculations. Generally, the best cutoffs to use is just a significance in terms of the gene vs control (padj < 0.05) and then directionality (up or down regulated). Anything more can get a bit dicey. \n\nORA is calculated by taking the number of genes in your input list that are in the pathway in question over the size of your input list. If that ratio is higher or lower than expected based on the number of genes in that pathway compared to the total number of genes, you woud have enrichment or deenrichment. \n\nIn this case, Ill be using the standard [Gene Ontology database](http://geneontology.org/) as the reference. This is a community curated list of pathways essentially, and is split in to biological processes, cellular component, and molecular function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here I will use just one sample again.First by subsetting it to just the significant genes\ncell1bug <- subset(Cell1Bug_vs_Control, padj < 0.05)\n\n#If I also wanted to filter for just the upregulated genes I could add something like this\n#cell1bug_ora <- subset(cell1bug_ora, log2FoldChange >0)\n#But in this case I want all the signficant genes so I wont\n\n#Now I do some funkiness to get the list of genes\noriginal_gene_list <- cell1bug$log2FoldChange\nnames(original_gene_list) <- cell1bug$Gene\ngene_list <- na.omit(original_gene_list)\ngene_list <- sort(gene_list, decreasing=TRUE)\ncell1bug_ora_genes <- names(gene_list)\n\n#And do the actual ORA and plot\ncell1bug_ora <- enrichGO(gene=cell1bug_ora_genes,\n                        ont='BP',\n                        keyType='ENSEMBL',\n                        pvalueCutoff=0.05,\n                        OrgDb=organism,\n                        pAdjustMethod='none')\ncell1bug_ora_plot <- dotplot(cell1bug_ora, showCategory=10, font.size=10) + scale_y_discrete(labels=function(x) str_wrap(x, width=40))\n#Make a quick directory to store the output files\ndir.create('./Pathways/')\n#Make a table for the full output, likewise you could read it here with just head(cell1bug_ora)         \nwrite.csv(cell1bug_ora, file='./Pathways/Cell1Bug_ORA_GO_totalsig.csv')\nprint(cell1bug_ora_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can try exploring other databases as well with clusterProfiler. Included are things like [KEGG](https://www.genome.jp/kegg/), [WikiPathways](https://www.wikipathways.org/), [Reactome](http://bioconductor.org/packages/ReactomePA), etc. "},{"metadata":{},"cell_type":"markdown","source":"#### Functional Class Scoring\nFunctional class scoring is also commonly called gene set enrichement analysis (GSEA), which is also its most famous implementation by the Broad. Unlike ORA, FCS takes in to account all of the genes in the dataset, but is predicated on a ranking system instead. Generally this can be ranked by p-value or log2FoldChange, but also can include things like the Wald statistic which would factor both. The concept behind FCS is that lots of small changes that are technically insignficant may aggregate to form a signficant shift in an overall pathway, and thereby a phenotypic change. \n\nFor this case, Ill use a different database to demonstrate the flexibility of clusterProfiler and how you would convert to a different ID type than ensembl. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ill start it as above to keep things akin, but note how there is no filtering first. \noriginal_gene_list <- Cell1Bug_vs_Control$log2FoldChange\nnames(original_gene_list) <- Cell1Bug_vs_Control$Gene\n\n#Now we use the bitr function that is built in to clusterProfile to conver to EntrezIDs, and sort them for FCS\nids<-bitr(names(original_gene_list), fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=organism)\ndedup_ids = ids[!duplicated(ids[c(\"ENSEMBL\")]),]\nfcs_df = Cell1Bug_vs_Control[Cell1Bug_vs_Control$Gene %in% dedup_ids$ENSEMBL,]\nfcs_df$Entrez = dedup_ids$ENTREZID\ncell1bug_kegg_gene_list <- fcs_df$log2FoldChange\nnames(cell1bug_kegg_gene_list) <- fcs_df$Entrez\ncell1bug_kegg_gene_list<-na.omit(kegg_gene_list)\ncell1bug_kegg_gene_list = sort(cell1bug_kegg_gene_list, decreasing = TRUE)\n\ncell1bug_fcs <- gseKEGG(geneList=cell1bug_kegg_gene_list,\n                       organism=korg,\n                       nPerm=as.numeric(1000),\n                       pvalueCutoff=0.05,\n                       minGSSize=3,\n                       maxGSSize=800,\n                       verbose=FALSE,\n                       pAdjustMethod='none')\n\ncell1bug_fcs_plot <- dotplot(cell1bug_fcs, showCategory=10, font.size=10) + scale_y_discrete(labels=function(x) str_wrap(x, width=40))\n#Make a quick directory to store the output files\ndir.create('./Pathways/')\n#Make a table for the full output, likewise you could read it here with just head(cell1bug_ora)         \nwrite.csv(cell1bug_fcs, file='./Pathways/Cell1Bug_FCS_KEGG.csv')\nprint(cell1bug_fcs_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, could be fun to then test this out with different databases and tweaking some of the parameters to best fit your data. With FCS in particular, you can also plot out the classic GSEA plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#In this case we are just going to take the top pathway in the file\ncell1bug_fcsgsea_plot <- gseaplot(cell1bug_fcs, geneSetID=as.numeric(1), by='runningScore',title='First Pathway GSEA plot')\nprint(cell1bug_fcsgsea_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Single gene plots\nSingle genes plots are a great way to show something that you have focused in on. Sometimes a whole RNA-seq experiment is focused for one gene in the end, and this is a great way to show it across groups. "},{"metadata":{"trusted":true},"cell_type":"code","source":"index <- which(genetable=='Actb')\nens_gene_select <- genetable[as.numeric(index), \"Gene\"]\n\nfiltered <- t(log2((counts(dds[ens_gene_select, ], normalized=TRUE, replaced=FALSE)+.5))) %>%\n       merge(colData(dds), ., by=\"row.names\") %>%\n       gather(gene, expression, (ncol(.)-length(ens_gene_select)+1):ncol(.))\n\np <- ggplot(filtered, aes_string('Group', \"expression\", fill='Group'))\np <- p + geom_boxplot() + facet_wrap(~gene, scales=\"free_y\")\n\np <- p + xlab(' ') + ylab('Normalized log2 Expression') + theme(\n  plot.margin = unit(c(1,1,1,1), \"cm\"),\n  axis.text.x = element_text(angle = as.numeric(45),size=as.numeric(5)),\n  axis.text.y = element_text(size=as.numeric(5)),\n  plot.title=element_text(size=as.numeric(10)),\n  legend.position='bottom') + ggtitle('Actb gene plot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You could also plot these via violin plots as an alternative to box plots. "}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}